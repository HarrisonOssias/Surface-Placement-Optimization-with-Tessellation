# Testing Instructions

This document provides step-by-step instructions for testing the SPO-T system with your Kinect One sensor.

---

## ‚úÖ Pre-Test Checklist

Before testing, ensure:

- [ ] Kinect v2 SDK 2.0 is installed
- [ ] Kinect One sensor is connected via USB 3.0
- [ ] Python environment is set up (`conda activate SPO-T`)
- [ ] All dependencies installed (`pip install -r requirements.txt`)
- [ ] pykinect2 is patched (`python utils/setup_pykinect2.py`)
- [ ] Kinect appears in Windows Device Manager

---

## üß™ Test 1: Verify Kinect Connection

```bash
python utils/test_setup.py
```

**Expected output:**
```
‚úì Kinect initialized successfully
‚úì Color stream active
‚úì Depth stream active
‚úì All systems ready
```

**If errors occur:**
1. Reconnect Kinect sensor
2. Restart computer
3. Reinstall Kinect SDK 2.0

---

## üß™ Test 2: Test Integrated GUI

```bash
python run_placement_system.py
```

### Test Scenario A: Simple Box on Empty Desk

**Setup:**
1. Clear your desk completely
2. Place a medium-sized box (15-30cm) on a separate surface

**Test Steps:**
1. **Step 1 - Box Measurement**:
   - Point camera at box
   - Verify green bounding box appears
   - Check dimensions look reasonable
   - Press `SPACE` to capture
   - ‚úÖ Box dimensions printed to console

2. **Step 2 - Desk Scanning**:
   - Point camera at empty desk
   - Verify green overlay covers most of desk
   - Check angle indicator is green
   - Press `SPACE` to scan
   - ‚úÖ "Desk scanned" message appears

3. **Step 3 - Analysis**:
   - Wait for progress bar to complete (~2 seconds)
   - ‚úÖ Automatically advances to Step 4

4. **Step 4 - Results**:
   - Verify "‚úì PLACEMENT FEASIBLE" appears
   - Check 3D box visualization
   - Verify clearance arrows are visible
   - Check info panel has reasonable values
   - Press `S` to save screenshot
   - ‚úÖ Screenshot saved to `data/captures/`

**Expected Result:** ‚úÖ FEASIBLE (empty desk should always fit box)

### Test Scenario B: Box on Cluttered Desk

**Setup:**
1. Add objects to desk (books, laptop, etc.)
2. Leave some free space

**Test Steps:**
- Repeat Test A steps with cluttered desk
- Expected: May be feasible or not, depending on free space
- Verify free space overlay shows correct regions

**Success Criteria:**
- Free space overlay matches visual reality
- Placement decision makes logical sense
- Console output matches GUI display

### Test Scenario C: Box on Completely Full Desk

**Setup:**
1. Fill entire desk with objects

**Test Steps:**
- Repeat Test A steps with full desk
- Expected Result: ‚úó NOT FEASIBLE
- Reason should be "No space available" or similar

**Success Criteria:**
- System correctly identifies lack of space
- Clear reason provided

---

## üß™ Test 3: Detection Method Comparison

```bash
# Must complete Test 2 first
python run_placement_system.py
```

**Test Steps:**

1. **Traditional CV Mode (Default)**:
   - Complete box measurement
   - Note dimensions printed
   - Take screenshot

2. **YOLO Mode** (if model trained):
   - Press `R` to reset
   - Press `M` to toggle to YOLO
   - Repeat box measurement with same box
   - Note dimensions
   - Compare with Traditional CV

**Compare:**
- Dimension accuracy (measure box with ruler for ground truth)
- Detection speed (observe responsiveness)
- Reliability (try multiple times)

**Expected Results:**
- Traditional CV: ¬±5-10cm error, faster
- YOLO: ¬±1-2cm error, slightly slower

---

## üß™ Test 4: Edge Cases

### Test 4A: Very Small Box (<10cm)
- May not be detected
- Expected: "No box detected" warning

### Test 4B: Very Large Box (>50cm)
- Should be detected
- Likely not feasible on normal desk
- Expected: "Box too large" reason

### Test 4C: Reflective/Transparent Box
- May have detection issues
- Expected: Poor dimension accuracy or no detection

### Test 4D: Camera Too Close (<0.3m)
- Depth data may be noisy
- Expected: Unstable detection

### Test 4E: Camera Too Far (>2m)
- Resolution drops
- Expected: Less accurate dimensions

---

## üß™ Test 5: Capture Test Scenarios

Create test scenarios for evaluation:

```bash
python run_placement_system.py
```

### Scenario Set to Capture:

1. **scenario_01**: Empty desk, small box (15cm)
   - Should fit: YES
   - Press `S` to save

2. **scenario_02**: Empty desk, medium box (25cm)
   - Should fit: YES
   - Press `S` to save

3. **scenario_03**: Empty desk, large box (40cm)
   - Should fit: DEPENDS on desk size
   - Press `S` to save

4. **scenario_04**: Moderately cluttered, small box
   - Should fit: YES
   - Press `S` to save

5. **scenario_05**: Moderately cluttered, medium box
   - Should fit: MAYBE
   - Press `S` to save

6. **scenario_06**: Heavily cluttered, any box
   - Should fit: NO
   - Press `S` to save

### After Capturing:

For each scenario, create `ground_truth.json`:

```bash
cd data/test_scenarios/scenario_01
# Create ground_truth.json manually
```

**Template:**
```json
{
  "scenario_id": "scenario_01",
  "box_dimensions": [0.15, 0.10, 0.08],
  "should_fit": true,
  "desk_free_percentage": 85.0,
  "notes": "Empty desk, small box"
}
```

**Measure box_dimensions with ruler!**

---

## üß™ Test 6: Run Evaluation

After capturing scenarios:

```bash
python src/evaluation/evaluate_system.py
```

**Expected output:**
- Evaluation report saved to `evaluation_results.md`
- Console summary with metrics

**Review:**
- Check dimension errors (MAE)
- Verify placement decisions match ground truth
- Compare Traditional CV vs YOLO (if available)

---

## üß™ Test 7: YOLO Training (Optional, 2-6 hours)

Only if you want to test YOLO detection:

### Step 1: Verify Dataset

```bash
python prepare_dataset.py
```

**Expected:** Dataset verification passes

### Step 2: Start Training

```bash
python src/training/train_yolo.py \
  --dataset_path "C:\Users\Sarri\Downloads\rgbd-scenes-v2_imgs\rgbd-scenes-v2" \
  --epochs 50 \
  --model_size n
```

**Expected:**
- Training starts (takes 2-6 hours)
- Progress printed each epoch
- Model saved to `models/runs/detect/box_detection/weights/best.pt`

### Step 3: Test Trained Model

```bash
python run_placement_system.py
# Press 'M' to toggle YOLO
```

**Expected:**
- YOLO mode activates
- Better dimension accuracy than Traditional CV

---

## üìã Test Results Checklist

Mark each test as you complete it:

### Basic Functionality
- [ ] Kinect connection verified
- [ ] GUI launches without errors
- [ ] Step 1 (Box Measurement) works
- [ ] Step 2 (Desk Scanning) works
- [ ] Step 3 (Analysis) completes
- [ ] Step 4 (Results) displays correctly

### Detection Quality
- [ ] Box detection works on various sizes
- [ ] Dimensions are approximately correct (¬±5-10cm)
- [ ] Free space overlay matches visual reality
- [ ] Placement decisions make logical sense

### Features
- [ ] Screenshot save works (`S` key)
- [ ] Back button works (`B` key)
- [ ] Reset works (`R` key)
- [ ] Method toggle works (`M` key) if YOLO trained

### Test Scenarios
- [ ] Captured scenario_01 (empty desk, small box)
- [ ] Captured scenario_02 (empty desk, medium box)
- [ ] Captured scenario_03 (empty desk, large box)
- [ ] Captured scenario_04 (cluttered desk, small box)
- [ ] Captured scenario_05 (cluttered desk, medium box)
- [ ] Captured scenario_06 (full desk, any box)
- [ ] Created ground_truth.json for each scenario
- [ ] Ran evaluation successfully

### Optional (YOLO)
- [ ] Dataset verified
- [ ] YOLO training completed
- [ ] YOLO model tested in GUI
- [ ] YOLO vs CV comparison done

---

## üêõ Common Issues During Testing

### Issue: "No module named 'pykinect2'"
**Solution:** `conda activate SPO-T` then `pip install -r requirements.txt`

### Issue: "Kinect not detected"
**Solution:** Check USB 3.0 connection, restart Kinect service

### Issue: "Detection very slow"
**Solution:** Close other apps, use Traditional CV mode

### Issue: "Box not detected"
**Solution:** Better lighting, move box closer, try different material

### Issue: "Free space overlay doesn't match reality"
**Solution:** Adjust camera angle, ensure desk is horizontal, retry scan

### Issue: "Analysis step freezes"
**Solution:** Restart app, ensure enough RAM available

---

## üìä Expected Performance Metrics

Based on preliminary testing:

### Detection Accuracy
- **Traditional CV**: 40-60% detection rate, ¬±5-10cm dimension error
- **YOLO**: 80-95% detection rate, ¬±1-2cm dimension error

### Processing Speed
- **Box Detection**: 30-50ms per frame
- **Desk Scanning**: 50-100ms per frame
- **Feasibility Analysis**: 100-200ms total

### Placement Decisions
- **Accuracy**: 85-90% correct decisions
- **False Positives**: <5% (says feasible when not)
- **False Negatives**: 10-15% (says not feasible when it is)

### System Requirements
- **RAM**: ~2GB during operation
- **CPU**: Moderate usage (30-50%)
- **GPU**: Optional for YOLO (10x faster training)

---

## ‚úÖ Test Sign-Off

**Tester Name:** ________________

**Date:** ________________

**Hardware:**
- Kinect Model: Kinect One (Xbox One)
- Computer: ________________
- OS: Windows ___

**Test Results:**
- Basic Functionality: ‚¨ú Pass ‚¨ú Fail
- Detection Quality: ‚¨ú Pass ‚¨ú Fail
- Features: ‚¨ú Pass ‚¨ú Fail
- Test Scenarios: ‚¨ú Complete ‚¨ú Incomplete

**Notes:**
_______________________________________
_______________________________________
_______________________________________

**Ready for Demo Video:** ‚¨ú Yes ‚¨ú No

---

**Questions?** See `USAGE_GUIDE.md` for detailed usage instructions.

